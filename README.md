# ğŸ­ **MLOps Machine Maintenance â€” End-to-End CI/CD Automation Project**

This repository presents a **complete MLOps workflow** designed to predict when industrial machines may require maintenance or repair.
By combining **machine learning**, **containerisation**, **orchestration**, and **automation**, it delivers a **production-ready system** that continuously integrates, trains, and deploys updates â€” automatically.

<p align="center">
  <img src="img/flask/flask_app.png" alt="Flask Application Interface â€” MLOps Machine Maintenance" width="100%">
</p>



## ğŸŒ¸ **Project Overview**

This project unifies the **Machine Learning lifecycle** with **MLOps automation**, demonstrating how to build, train, containerise, deploy, and maintain a model in a **scalable, reproducible, and cloud-deployed environment**.
The application estimates the **likelihood of machine efficiency issues** based on operational parameters, providing insights into **when maintenance is likely needed**.

Key technologies include **Python**, **Flask**, **Docker**, **Kubernetes (Minikube)**, **Google Cloud Platform (GCP)**, **Jenkins**, **ArgoCD**, and **GitHub Webhooks**.



## âš™ï¸ **Workflow Summary**

This project followed a structured 13-stage development lifecycle, each step building upon the last to achieve a seamless CI/CD automation pipeline.

### **00 â€” Project Setup**

Created the foundational project structure, virtual environment, and configuration files for reproducibility.

### **01 â€” Data Processing**

Prepared the raw machine sensor data, including cleaning, encoding, feature scaling, and splitting into train/test sets.

### **02 â€” Model Training**

Developed and evaluated a **Logistic Regression model** to predict machine maintenance likelihood, saving artefacts to disk.

### **03 â€” Training Pipeline**

Integrated preprocessing and model training into one **automated workflow script (`training_pipeline.py`)**, enabling full pipeline execution with a single command.

### **04 â€” Flask Application**

Built a **Flask web interface** that allows users to input machine parameters and receive maintenance predictions in real time.

### **05 â€” Docker and Kubernetes Manifests**

Created a **Dockerfile** to containerise the Flask app and developed **Kubernetes manifests** (`deployment.yaml` and `service.yaml`) for scalable deployment and public exposure.

### **06 â€” Google Cloud Platform Setup**

Provisioned a **GCP Virtual Machine** instance to host the entire workflow.
Configured the instance for **Docker installation** and VM networking.

### **07 â€” Minikube Installation and Setup**

Installed and configured **Minikube** within the VM to simulate a local Kubernetes cluster.
Deployed the containerised application for initial end-to-end testing.

### **08 â€” Jenkins Installation (Docker-in-Docker)**

Deployed **Jenkins** in a Docker container using a Docker-in-Docker (DinD) approach, ensuring CI/CD orchestration could build, push, and deploy containers dynamically.

### **09 â€” GitHub Integration with Jenkins**

Connected **Jenkins** to the GitHub repository using **personal access tokens**, allowing Jenkins to fetch source code directly from GitHub.

### **10 â€” Build and Push Docker Image**

Configured the Jenkins pipeline to:

1. Build Docker images from the source code.
2. Push images to a **DockerHub repository** using stored credentials.

This completed the **Continuous Integration (CI)** stage.

### **11 â€” Continuous Deployment with ArgoCD**

Installed and configured **ArgoCD** to handle Continuous Deployment (CD).
The Jenkins pipeline triggered ArgoCD to sync GitHub code changes with the Kubernetes cluster, deploying the latest image automatically.

### **12 â€” Webhooks Integration**

Introduced **GitHub Webhooks** to automate pipeline execution.
Now, whenever code is pushed to GitHub, Jenkins automatically triggers the pipeline, builds the Docker image, updates ArgoCD, and redeploys the application â€” achieving **true automation**.

### **13 â€” Final Automation**

At this stage, the project became fully operational:
A single **GitHub push** cascades through Jenkins, Docker, Kubernetes, and ArgoCD â€” updating the live Flask application automatically.



## ğŸ§  **Key Features**

* **End-to-End Automation** â€” Complete CI/CD workflow from data ingestion to live deployment.
* **Containerised ML Pipeline** â€” Ensures consistency across environments.
* **Kubernetes Orchestration** â€” Provides scalability and reliability.
* **GitOps with ArgoCD** â€” Automates syncing between GitHub and cluster state.
* **Webhook-Driven Triggers** â€” Eliminates manual builds; pipelines run on every push.
* **Cloud-Hosted Architecture** â€” Fully hosted on a Google Cloud VM instance.



## ğŸ—‚ï¸ **Final Project Structure**

```text
mlops_machine_maintenance/
â”œâ”€â”€ .venv/                            # ğŸ§© Local virtual environment
â”œâ”€â”€ artifacts/
â”‚   â”œâ”€â”€ raw/
â”‚   â”‚   â””â”€â”€ data.csv                  # âš™ï¸ Raw machine sensor dataset
â”‚   â”œâ”€â”€ processed/                    # ğŸ’¾ Processed data and scaler
â”‚   â”‚   â”œâ”€â”€ X_train.pkl
â”‚   â”‚   â”œâ”€â”€ X_test.pkl
â”‚   â”‚   â”œâ”€â”€ y_train.pkl
â”‚   â”‚   â”œâ”€â”€ y_test.pkl
â”‚   â”‚   â””â”€â”€ scaler.pkl
â”‚   â””â”€â”€ models/                       # ğŸ§  Trained model artefacts
â”‚       â””â”€â”€ model.pkl
â”œâ”€â”€ manifests/                        # â˜¸ï¸ Kubernetes configuration files
â”‚   â”œâ”€â”€ deployment.yaml               # Defines pods, replicas, and container spec
â”‚   â””â”€â”€ service.yaml                  # LoadBalancer service exposing the app
â”œâ”€â”€ pipeline/                         # âš™ï¸ Workflow orchestration
â”‚   â””â”€â”€ training_pipeline.py          # End-to-end data processing + model training
â”œâ”€â”€ src/                              # ğŸ§  Core Python modules
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ custom_exception.py           # Unified error handling
â”‚   â”œâ”€â”€ logger.py                     # Centralised logging configuration
â”‚   â”œâ”€â”€ data_processing.py            # Preprocessing and scaling
â”‚   â””â”€â”€ model_training.py             # Model training and evaluation
â”œâ”€â”€ static/                           # ğŸŒˆ Front-end styling and assets
â”‚   â”œâ”€â”€ style.css
â”‚   â””â”€â”€ img/
â”œâ”€â”€ templates/                        # ğŸ§© HTML templates for Flask
â”‚   â””â”€â”€ index.html
â”œâ”€â”€ img/
â”‚   â””â”€â”€ flask/
â”œâ”€â”€ app.py                            # ğŸŒ Flask app for prediction interface
â”œâ”€â”€ Dockerfile                        # ğŸ³ Container build file
â”œâ”€â”€ .gitignore                        # ğŸš« Ignore rules for Git
â”œâ”€â”€ .python-version                   # ğŸ Python version pin
â”œâ”€â”€ pyproject.toml                    # âš™ï¸ Project metadata
â”œâ”€â”€ requirements.txt                  # ğŸ“¦ Python dependencies
â”œâ”€â”€ setup.py                          # ğŸ”§ Editable install support
â””â”€â”€ uv.lock                           # ğŸ”’ Locked dependency versions
```



## âœ… **Conclusion**

This project demonstrates how to operationalise a **machine learning model** using **real-world MLOps practices** â€” transforming it from a local experiment into a **cloud-deployed, continuously updated system**.

Through the integration of **GitHub**, **Jenkins**, **Docker**, **Kubernetes**, **ArgoCD**, and **Webhooks**, the pipeline now achieves **true continuous delivery**:
every code push automatically rebuilds, redeploys, and synchronises the live application.

This marks the completion of the **MLOps Machine Maintenance** project â€” a full demonstration of data science meeting production engineering.